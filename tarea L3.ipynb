{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de16ac05-1760-49ad-b40c-327a96a8e846",
   "metadata": {},
   "source": [
    "# Laboratorio de regresión - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0fb70-ca43-47f7-bbfd-fd06ca0e25f2",
   "metadata": {},
   "source": [
    "## Significancia de factores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043c593-39d1-405c-b92e-487314170cf6",
   "metadata": {},
   "source": [
    "|                |   |\n",
    ":----------------|---|\n",
    "| **Nombre**     |  Regina Tamayo León  |\n",
    "| **Fecha**      | 03 feb 2026  |\n",
    "| **Expediente** | 757857  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfabde4-866e-4f00-8a37-9d57f2bebbb6",
   "metadata": {},
   "source": [
    "Descarga el archivo de publicidad y carga los datos (Advertising.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07527ab6-7c18-48b5-9779-d5e6e5da289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  radio  newspaper  sales\n",
       "0           1  230.1   37.8       69.2   22.1\n",
       "1           2   44.5   39.3       45.1   10.4\n",
       "2           3   17.2   45.9       69.3    9.3\n",
       "3           4  151.5   41.3       58.5   18.5\n",
       "4           5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('Advertising.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f041ab-56b6-4b63-921c-8671831b09ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  200 non-null    int64  \n",
      " 1   TV          200 non-null    float64\n",
      " 2   radio       200 non-null    float64\n",
      " 3   newspaper   200 non-null    float64\n",
      " 4   sales       200 non-null    float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81535ac-87ca-490e-89e7-0564c31f73f0",
   "metadata": {},
   "source": [
    "**¿Hay alguna relación entre el presupuesto para publicidad y las ventas?**\n",
    "\n",
    "Nuestra primera meta debe ser determinar si hay evidencia en los datos de que haya una asociación entre estas variables.\n",
    "\n",
    "- ¿Por qué? ¿Qué resultaría si nos diéramos cuenta de la falta de relación entre el presupuesto de publicidad y las ventas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed6dff-daa6-4680-ae46-1892fbe61743",
   "metadata": {},
   "source": [
    "Antes de tomar decisiones, se debe comprobar si la publicidad tiene algún impacto real en el comportamiento de las ventas. Cuando la información revela que no existe un vínculo entre ambas, aumentar el gasto publicitario no implica necesariamente vender más, por lo que no resulta útil considerarla como un factor predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff47351-fa8b-4c19-93ce-d68dce869913",
   "metadata": {},
   "source": [
    "**¿Qué tan fuerte es esta relación?**\n",
    "Asumiendo que existe esta relación, ¿nos sirve conocer el impacto que tiene invertir en publicidad en las ventas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f729ab-b3c5-45f2-be4d-679b009f3d98",
   "metadata": {},
   "source": [
    "Es importante saber qué tan fuerte es la relación porque así podemos entender qué tanto cambian las ventas cuando se invierte más en publicidad. Esto nos ayuda a decidir si realmente conviene aumentar el presupuesto y si eso tiene un efecto real en los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd03e68-778f-49cc-9161-a2fff241af56",
   "metadata": {},
   "source": [
    "**¿Cuáles medios están asociados con las ventas? ¿Qué tan grande es la asociación entre un medio específico y las ventas?**\n",
    "\n",
    "Hay 3 medios distintos en los datos. ¿Sirve invertir en los 3? ¿Conviene más invertir sólo en uno?\n",
    "\n",
    "**¿Qué tan seguros estamos de que podríamos predecir ventas futuras?**\n",
    "\n",
    "**¿La relación es lineal?**\n",
    "\n",
    "**¿Hay sinergia entre estos medios?**\n",
    "\n",
    "Puede ser que gastar \\\\$50,000 en publicidad y otros \\\\$50,000 en radio es mejor opción que gastar \\\\$100,000 en televisión. A esto le llamamos efecto de interacción.\n",
    "\n",
    "Podemos usar regresión lineal para responder todas estas preguntas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f1c79-027e-4af9-b61b-82e4a45df0bb",
   "metadata": {},
   "source": [
    "Realiza una regresión lineal:\n",
    "\n",
    "$$ \\text{ventas} \\approx \\beta_0 + (\\beta_1)(\\text{TV})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82dd5260-ff12-4261-b325-40f70c7e3783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0: 7.0325935491276885\n",
      "b1: [0.04753664]\n"
     ]
    }
   ],
   "source": [
    "x = np.array (df[['TV']])\n",
    "y = np.array (df['sales'])\n",
    "lr = LinearRegression()\n",
    "lr.fit(x,y)\n",
    "beta_0 =lr.intercept_\n",
    "print(\"b0:\", beta_0)\n",
    "\n",
    "beta_1 = lr.coef_\n",
    "print(\"b1:\", beta_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ba655-7b09-482a-992f-02380dd54209",
   "metadata": {},
   "source": [
    "### Verificando la precisión de nuestros coeficientes estimados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30733e87-7be2-477f-84c2-d430ad1a2a5d",
   "metadata": {},
   "source": [
    "Recuerda que en el mundo real hay ruidos y errores de medición. Siempre se asume que la verdadera relación entre $X$ y $Y$ es $$Y = \\beta_0 + \\beta_1 X + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af33c415-790e-4e28-bcd5-8f94ac545822",
   "metadata": {},
   "source": [
    "Se asume que el término de error es independiente de $X$ (el error siempre es el mismo sin importar el valor de $X$). Este modelo describe a la *línea de regresión de la población*, que es la mejor aproximación de la verdadera relación entre $X$ y $Y$. Cuando usamos mínimos cuadrados encontramos la *línea de mínimos cuadrados*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d80b2d-2c96-4fa7-8348-29e8215e4e2e",
   "metadata": {},
   "source": [
    "¿Cuál es la diferencia entre población y muestra?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec345b97-255d-45a2-95ea-487212a02644",
   "metadata": {},
   "source": [
    "población:todo el conjunto de elementos que se quiere estudiar. \n",
    "muestra:solo una parte de esa población ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74ba36-845f-44fe-89e4-442b66f44d9d",
   "metadata": {},
   "source": [
    "¿Cuál crees que sea la diferencia entre hacer una regresión con todos los datos de la población y una muestra de ella?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563051a-01a3-4a4e-bff2-f12c7d113b15",
   "metadata": {},
   "source": [
    "Cuando se realiza una regresión usando todos los datos de la población, el resultado muestra la relación real tal como es, ya que se cuenta con toda la información disponible. En cambio, al trabajar solo con una muestra, la regresión solo representa una estimación, porque depende de los datos seleccionados y puede variar si se toma una muestra diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123335b-5299-4f2e-ac8e-4b1e40754221",
   "metadata": {},
   "source": [
    "La línea de regresión de la población no se puede observar. El concepto de comparar estas líneas es una extensión natural del acercamiento estadístico estándar de usar información de una muestra para estimar características de una población grande."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d26b9-18de-4467-a836-3f75b228a363",
   "metadata": {},
   "source": [
    "Imagina que quieres encontrar la altura promedio de un mexicano $\\mu$. Medir a todos y cada uno de los mexicanos en situaciones similares, con la misma regla, mismo operador, y otras incontables formas de minimizar la variación de la medida es una tarea imposible. Lo que podemos asumir es que $\\hat{\\mu} = \\bar{y}$. La media poblacional y la media muestral son diferentes, pero la media muestral es usualmente un buen estimado.\n",
    "\n",
    "De la misma manera, como no contamos con el 100% de la información para hacer una regresión, los coeficientes $\\beta_0$ y $\\beta_1$ son desconocidos. Podemos estimarlos usando mínimos cuadrados, encontrando $\\hat{\\beta_0}$ y $\\hat{\\beta_1}$. Puede que las muestras que tengamos en ese momento estén un poco por encima de la media, pero otras muestras en otro momento puede que estén debajo de la media. En general, esperamos que el promedio de las aproximaciones $\\hat{\\mu}$ aproxime a $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff6312-57a0-4c9f-aaa9-f22f6294c71c",
   "metadata": {},
   "source": [
    "Esto lleva a la pregunta: ¿qué tan cercanos son nuestros coeficientes estimados a los verdaderos coeficientes? Utilizamos el concepto de error estándar para evaluar esto.\n",
    "\n",
    "$$ \\text{Var}(\\hat{\\mu})=\\text{SE}(\\hat{\\mu})^2 = \\frac{\\sigma^2}{n} $$\n",
    "\n",
    "Donde $\\sigma$ es la desviación estándar de cada una de las observaciones $y_i$ de $Y$. El error estándar nos dice la cantidad promedio que el estimado difiere del valor verdadero. Podemos ver en la fórmula que entre más observaciones tengamos el error se hace más pequeño. Las fórmulas para errores estándar de $\\hat{\\beta_0}$ y $\\hat{\\beta_1}$ son:\n",
    "\n",
    "$$ \\text{SE}(\\hat{\\beta_0})^2 = \\sigma^2 [\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2}]$$\n",
    "\n",
    "$$ \\text{SE}(\\hat{\\beta_1})^2 = \\frac{\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2}$$\n",
    "\n",
    "$$ \\sigma^2 = \\text{Var}(\\epsilon) = \\text{RSE}^2 = \\frac{\\text{RSS}}{n-p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661b6d7c-2274-462f-92ff-0e7be8ca742d",
   "metadata": {},
   "source": [
    "Para que estas fórmulas sean validas asumimos que los errores $\\epsilon_i$ tienen varianza común $\\sigma^2$ y que no están correlacionados.\n",
    "\n",
    "Calcula los errores estándar de los coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07843e5d-fa42-4266-9dda-7701a5700f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE b1: 0.0026838383539596546\n",
      "SE b0: 0.4566911323097188\n"
     ]
    }
   ],
   "source": [
    "n,p = x.shape\n",
    "xbar = np.mean(x)\n",
    "aux= np.sum((x - xbar)**2)\n",
    "y2= lr.predict(x)\n",
    "RSS = np.sum((y - y2)**2)\n",
    "var = RSS/(n-p)\n",
    "SE_1 = np.sqrt(var/aux)\n",
    "SE_0= SE_1 * np.sqrt(np.sum(x**2)/n)\n",
    "print(\"SE b1:\", SE_1)\n",
    "print(\"SE b0:\", SE_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2711ec-2380-4bce-ac68-007378e7b76c",
   "metadata": {},
   "source": [
    "Estos errores se pueden usar para calcular intervalos de confianza. Un intervalo de confianza del $95\\%$ se define como un rango de valores en el cuál se encuentra el desconocido valor verdadero con un $95\\%$ de probabilidad.\n",
    "\n",
    "Otra forma de verlo es que si tomamos muestras repetidas y construimos un intervalo de confianza para cada una, el $95\\%$ de los intervalos creados van a contener el valor verdadero. Para la regresión el intervalo de confianza del $95\\%$ toma la forma:\n",
    "\n",
    "$$ \\hat{\\beta_j} \\pm 2\\text{SE}(\\hat{\\beta_j})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71aed31-b058-4217-8d45-9686b9611511",
   "metadata": {},
   "source": [
    "Calcula los intervalos de confianza para los coeficientes estimados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b725487-4e48-471d-9c5a-547e7e176334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervalo de confianza b1: (array([0.04216896]), array([0.05290432]))\n",
      "Intervalo de confianza b0: (np.float64(6.119211284508251), np.float64(7.945975813747126))\n"
     ]
    }
   ],
   "source": [
    "int_izq1= beta_1-( SE_1*2)\n",
    "int_der1= beta_1+( SE_1*2)\n",
    "int_izq0= beta_0-( SE_0*2)\n",
    "int_der0= beta_0+( SE_0*2)\n",
    "print(\"Intervalo de confianza b1:\", (int_izq1, int_der1))\n",
    "print(\"Intervalo de confianza b0:\", (int_izq0, int_der0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3b3100-fb87-42de-9e74-75c72464bb7b",
   "metadata": {},
   "source": [
    "Los errores estándar también se usan para realizar pruebas de hipótesis. La prueba de hipótesis más común es probar la hipótesis nula de:\n",
    "\n",
    "$$ H_0: \\text{No hay relación entre } X \\text{ y } Y \\ \\ \\ \\ (\\beta_1=0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef288e-55fe-45fb-bb86-4bef282b5947",
   "metadata": {},
   "source": [
    "contra la hipótesis alternativa:\n",
    "$$ H_0: \\text{Hay alguna relación entre } X \\text{ y } Y \\ \\ \\ (\\beta_1 \\neq 0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0c27a-4a67-450c-b2ce-a65958938c25",
   "metadata": {},
   "source": [
    "Explica con tus palabras el significado de la hipótesis nula y la hipótesis alternativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7cb88-88a5-462f-84ec-6019911ebb64",
   "metadata": {},
   "source": [
    "Los errores estándar se utilizan para analizar si la relación que se observa entre las variables X y Y es significativa o si podría deberse al azar. Para esto se plantean dos hipótesis: la hipótesis nula establece que no existe relación entre las variables, es decir, que la publicidad no tiene efecto sobre las ventas, mientras que la hipótesis alternativa sostiene que sí existe una relación y que los cambios en X influyen en Y.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6404ea-89ae-45f0-9935-67dbd53b78c6",
   "metadata": {},
   "source": [
    "Para probal la hipótesis nula debemos determinar si nuestro estimado $\\hat{\\beta_1}$ de $\\beta_1$ está lo suficientemente alejado de cero para que podamos decir con confianza que este valor no es cero. \n",
    "\n",
    "¿Qué tan lejos? Depende de qué tanta confianza tengamos en el estimado encontrado. Si nuestro error estándar es pequeño y nuestro estimado está alejado de cero podríamos decir que hay muy poca probabilidad de que el valor verdadero sea 0. En cambio, si nuestro error estándar es grande y nuestro estimado está muy cerca de cero, entonces podrías ser que el valor verdadero sea cero y que no haya relación entre las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96161b14-6a16-41ea-aec8-0394f729447d",
   "metadata": {},
   "source": [
    "Se calcula un *estadístico t* dado por\n",
    "$$ t = \\frac{\\hat{\\beta_j} - \\mu}{\\text{SE}(\\hat{\\beta_j})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04296d-854b-4fcb-9c79-6b23b516f2f3",
   "metadata": {},
   "source": [
    "donde $\\mu$ es el valor contra el que queremos probar.\n",
    "\n",
    "Calcula el estadístico t para tus coeficientes estimados, usando como referencia la prueba de hipótesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68f15e0c-6c64-4ff5-a03c-8d72b639db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t para  b1: [17.71218463]\n"
     ]
    }
   ],
   "source": [
    "t= beta_1/SE_1\n",
    "print(\"t para  b1:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b101c1c-0570-4b3b-bb87-eb7b53e6ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t para b0: 15.399014895604157\n"
     ]
    }
   ],
   "source": [
    "t1= beta_0/SE_0\n",
    "print(\"t para b0:\", t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737b123-f4c5-403c-92f2-4800c79107d9",
   "metadata": {},
   "source": [
    "La distribución t tiene forma de campana y se parece bastante a la distribución normal cuando $n > 30$. Ya sólo es cuestión de calcular la probabilidad de observar cualquier número tal que su valor absoluto sea igual o mayor que el valor absoluto del estadístico t calculado. En otras palabras:\n",
    "$$ P(|x| \\geq |t|) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2ccf1-b4b1-4c0c-a15b-d4fdd2f4552a",
   "metadata": {},
   "source": [
    "A esta probabilidad la llamamos *p-value*. Un *p-value* pequeño indica que es poco probable que exista por puro azar una relación significativa entre predictor y respuesta, en caso de que no haya una asociación real entre predictor y respuesta. En otras palabras, el *p-value* te dice la probabilidad de que parezca que hay relación cuando no la hay.\n",
    "\n",
    "Si el *p-value* es pequeño, inferimos que sí hay una asociación entre el predictor y la respuesta, y **rechazamos la hipótesis nula**.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f17065-a71d-4322-8782-3e805df65d29",
   "metadata": {},
   "source": [
    "¿Qué tan pequeño? Depende de la aplicación. Un valor muy común es del $5\\%$.\n",
    "\n",
    "Utiliza el siguiente código para calcular el *p-value* para tus coeficientes\n",
    "\n",
    "`from scipy import stats`\n",
    "\n",
    "`p_bj = 2*(1 - stats.t.cdf(np.abs(t_bj), n-p))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a542d04-f9cb-4ea2-9af1-ca79d1539860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-valor b1: [0.]\n",
      "p-valor b0: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "p_b1 = 2*(1 - stats.t.cdf(np.abs(t), df=n - p))\n",
    "print(\"p-valor b1:\", p_b1)\n",
    "p_b0 = 2*(1 - stats.t.cdf(np.abs(t1), df=n - p))\n",
    "print(\"p-valor b0:\", p_b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9ad17-db40-405e-b88a-d0af8a05aacf",
   "metadata": {},
   "source": [
    "¿Se rechaza la hipótesis nula? ¿Qué significa?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f861e-f191-47f8-9510-7444ab416756",
   "metadata": {},
   "source": [
    "Si se rechaza la h0 o nula indica que si tienen relacion las variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a994d1a-6187-491c-a518-7971cebe3c0a",
   "metadata": {},
   "source": [
    "Realiza otras dos regresiones. Ya tienes hecha la regresión de ventas dado el gasto en publicidad de TV. Realiza la regresión para gastos en radio y gastos en periódico. Organiza las respuestas para que debajo de esta celda se tenga:\n",
    "- Título de regresión\n",
    "- Coeficientes estimados\n",
    "- Errores estándar de los coeficientes\n",
    "- Intervalos de confianza\n",
    "- Estadísticos t\n",
    "- p-values\n",
    "- Observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbfaed5f-f044-43e4-90b7-29144d8b8f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0_per: 12.35140706927816\n",
      "b1_per: [0.0546931]\n",
      "SE b1_per: 0.01653402188104787\n",
      "SE b0_per: 0.6198568639061094\n",
      "Intervalo de confianza b1_per: (array([0.02162505]), array([0.08776114]))\n",
      "Intervalo de confianza b0_per: (np.float64(11.11169334146594), np.float64(13.59112079709038))\n",
      "t para b1_per: [3.30791255]\n",
      "t para b0_per: 19.926224566497734\n",
      "p-valor b1_per: [0.00111543]\n",
      "p-valor b0_per: 0.0\n"
     ]
    }
   ],
   "source": [
    "x_per = np.array(df[['newspaper']])\n",
    "y_per = np.array(df['sales'])\n",
    "\n",
    "lr_per = LinearRegression()\n",
    "lr_per.fit(x_per, y_per)\n",
    "\n",
    "beta_0_per = lr_per.intercept_\n",
    "print(\"b0_per:\", beta_0_per)\n",
    "\n",
    "beta_1_per = lr_per.coef_\n",
    "print(\"b1_per:\", beta_1_per)\n",
    "\n",
    "n_per, p_per = x_per.shape\n",
    "xbar_per = np.mean(x_per)\n",
    "aux_per = np.sum((x_per - xbar_per)**2)\n",
    "\n",
    "y2_per = lr_per.predict(x_per)\n",
    "RSS_per = np.sum((y_per - y2_per)**2)\n",
    "var_per = RSS_per / (n_per - p_per)\n",
    "\n",
    "SE_1_per = np.sqrt(var_per / aux_per)\n",
    "SE_0_per = SE_1_per * np.sqrt(np.sum(x_per**2) / n_per)\n",
    "\n",
    "print(\"SE b1_per:\", SE_1_per)\n",
    "print(\"SE b0_per:\", SE_0_per)\n",
    "\n",
    "int_izq1_per = beta_1_per - (SE_1_per * 2)\n",
    "int_der1_per = beta_1_per + (SE_1_per * 2)\n",
    "int_izq0_per = beta_0_per - (SE_0_per * 2)\n",
    "int_der0_per = beta_0_per + (SE_0_per * 2)\n",
    "\n",
    "print(\"Intervalo de confianza b1_per:\", (int_izq1_per, int_der1_per))\n",
    "print(\"Intervalo de confianza b0_per:\", (int_izq0_per, int_der0_per))\n",
    "\n",
    "t_per = beta_1_per / SE_1_per\n",
    "print(\"t para b1_per:\", t_per)\n",
    "\n",
    "t0_per = beta_0_per / SE_0_per\n",
    "print(\"t para b0_per:\", t0_per)\n",
    "\n",
    "p_b1_per = 2 * (1 - stats.t.cdf(np.abs(t_per), df=n_per - p_per))\n",
    "print(\"p-valor b1_per:\", p_b1_per)\n",
    "\n",
    "p_b0_per = 2 * (1 - stats.t.cdf(np.abs(t0_per), df=n_per - p_per))\n",
    "print(\"p-valor b0_per:\", p_b0_per)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "166901b6-333e-49f2-bd64-52f13d866e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0_radio: 9.311638095158285\n",
      "b1_radio: [0.20249578]\n",
      "SE b1_radio: 0.02035995708035237\n",
      "SE b0_radio: 0.5614843921510496\n",
      "Intervalo de confianza b1_radio: (array([0.16177587]), array([0.2432157]))\n",
      "Intervalo de confianza b0_radio: (np.float64(8.188669310856186), np.float64(10.434606879460384))\n",
      "t para b1_radio: [9.94578636]\n",
      "t para b0_radio: 16.58396604665243\n",
      "p-valor b1_radio: [0.]\n",
      "p-valor b0_radio: 0.0\n"
     ]
    }
   ],
   "source": [
    "x_radio = np.array(df[['radio']])\n",
    "y_radio = np.array(df['sales'])\n",
    "\n",
    "lr_radio = LinearRegression()\n",
    "lr_radio.fit(x_radio, y_radio)\n",
    "\n",
    "beta_0_radio = lr_radio.intercept_\n",
    "print(\"b0_radio:\", beta_0_radio)\n",
    "\n",
    "beta_1_radio = lr_radio.coef_\n",
    "print(\"b1_radio:\", beta_1_radio)\n",
    "\n",
    "n_radio, p_radio = x_radio.shape\n",
    "xbar_radio = np.mean(x_radio)\n",
    "aux_radio = np.sum((x_radio - xbar_radio)**2)\n",
    "\n",
    "y2_radio = lr_radio.predict(x_radio)\n",
    "RSS_radio = np.sum((y_radio - y2_radio)**2)\n",
    "var_radio = RSS_radio / (n_radio - p_radio)\n",
    "\n",
    "SE_1_radio = np.sqrt(var_radio / aux_radio)\n",
    "SE_0_radio = SE_1_radio * np.sqrt(np.sum(x_radio**2) / n_radio)\n",
    "\n",
    "print(\"SE b1_radio:\", SE_1_radio)\n",
    "print(\"SE b0_radio:\", SE_0_radio)\n",
    "\n",
    "int_izq1_radio = beta_1_radio - (SE_1_radio * 2)\n",
    "int_der1_radio = beta_1_radio + (SE_1_radio * 2)\n",
    "int_izq0_radio = beta_0_radio - (SE_0_radio * 2)\n",
    "int_der0_radio = beta_0_radio + (SE_0_radio * 2)\n",
    "\n",
    "print(\"Intervalo de confianza b1_radio:\", (int_izq1_radio, int_der1_radio))\n",
    "print(\"Intervalo de confianza b0_radio:\", (int_izq0_radio, int_der0_radio))\n",
    "\n",
    "t_radio = beta_1_radio / SE_1_radio\n",
    "print(\"t para b1_radio:\", t_radio)\n",
    "\n",
    "t0_radio = beta_0_radio / SE_0_radio\n",
    "print(\"t para b0_radio:\", t0_radio)\n",
    "\n",
    "p_b1_radio = 2 * (1 - stats.t.cdf(np.abs(t_radio), df=n_radio - p_radio))\n",
    "print(\"p-valor b1_radio:\", p_b1_radio)\n",
    "\n",
    "p_b0_radio = 2 * (1 - stats.t.cdf(np.abs(t0_radio), df=n_radio - p_radio))\n",
    "print(\"p-valor b0_radio:\", p_b0_radio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556988ae-3656-428d-817b-76f9e1534f46",
   "metadata": {},
   "source": [
    "## Regresión lineal múltiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943698d8-7f84-4245-8be3-e4c8f34be5da",
   "metadata": {},
   "source": [
    "En lugar de hacer una regresión para cada factor independiente, quizás se puede extender el modelo para que tenga varios factores dentro:\n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p + \\epsilon $$\n",
    "\n",
    "Para nuestro ejemplo de publicidad:\n",
    "\n",
    "$$ \\text{sales} = \\beta_0 + \\beta_1 (\\text{TV}) + \\beta_2 (\\text{radio}) + \\beta_3 (\\text{newspaper}) + \\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cd89a-0c25-4e1d-9213-292807e17ccf",
   "metadata": {},
   "source": [
    "Utiliza la librería `statsmodels` para realizar la regresión. Por defecto la librería statsmodels no toma en cuenta el intercepto ($\\beta_0$), por lo que se tendrá que agregar una columna de unos de tamaño *n* a la matriz X.\n",
    "\n",
    "`import statsmodels.api as sm`\n",
    "\n",
    "`ols = sm.OLS(Y, X)`\n",
    "\n",
    "`results = ols.fit()`\n",
    "\n",
    "`results.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7a3bd74-0f56-4199-a327-278c3ec9919e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   570.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Feb 2026</td> <th>  Prob (F-statistic):</th> <td>1.58e-96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:37:21</td>     <th>  Log-Likelihood:    </th> <td> -386.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   780.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   196</td>      <th>  BIC:               </th> <td>   793.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.9389</td> <td>    0.312</td> <td>    9.422</td> <td> 0.000</td> <td>    2.324</td> <td>    3.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1885</td> <td>    0.009</td> <td>   21.893</td> <td> 0.000</td> <td>    0.172</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0458</td> <td>    0.001</td> <td>   32.809</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0010</td> <td>    0.006</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.013</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>60.414</td> <th>  Durbin-Watson:     </th> <td>   2.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 151.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.327</td> <th>  Prob(JB):          </th> <td>1.44e-33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.332</td> <th>  Cond. No.          </th> <td>    454.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.897   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.896   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     570.3   \\\\\n",
       "\\textbf{Date:}             & Tue, 03 Feb 2026 & \\textbf{  Prob (F-statistic):} &  1.58e-96   \\\\\n",
       "\\textbf{Time:}             &     13:37:21     & \\textbf{  Log-Likelihood:    } &   -386.18   \\\\\n",
       "\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               } &     780.4   \\\\\n",
       "\\textbf{Df Residuals:}     &         196      & \\textbf{  BIC:               } &     793.6   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       2.9389  &        0.312     &     9.422  &         0.000        &        2.324    &        3.554     \\\\\n",
       "\\textbf{x1}    &       0.1885  &        0.009     &    21.893  &         0.000        &        0.172    &        0.206     \\\\\n",
       "\\textbf{x2}    &       0.0458  &        0.001     &    32.809  &         0.000        &        0.043    &        0.049     \\\\\n",
       "\\textbf{x3}    &      -0.0010  &        0.006     &    -0.177  &         0.860        &       -0.013    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 60.414 & \\textbf{  Durbin-Watson:     } &    2.084  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  151.241  \\\\\n",
       "\\textbf{Skew:}          & -1.327 & \\textbf{  Prob(JB):          } & 1.44e-33  \\\\\n",
       "\\textbf{Kurtosis:}      &  6.332 & \\textbf{  Cond. No.          } &     454.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.897\n",
       "Model:                            OLS   Adj. R-squared:                  0.896\n",
       "Method:                 Least Squares   F-statistic:                     570.3\n",
       "Date:                Tue, 03 Feb 2026   Prob (F-statistic):           1.58e-96\n",
       "Time:                        13:37:21   Log-Likelihood:                -386.18\n",
       "No. Observations:                 200   AIC:                             780.4\n",
       "Df Residuals:                     196   BIC:                             793.6\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.9389      0.312      9.422      0.000       2.324       3.554\n",
       "x1             0.1885      0.009     21.893      0.000       0.172       0.206\n",
       "x2             0.0458      0.001     32.809      0.000       0.043       0.049\n",
       "x3            -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
       "==============================================================================\n",
       "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
       "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
       "Kurtosis:                       6.332   Cond. No.                         454.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "b = np.array (df[['radio','TV','newspaper']])\n",
    "y = np.array (df['sales'])\n",
    "b2 = sm.add_constant(b)\n",
    "model = sm.OLS(y, b2)\n",
    "results = model.fit()\n",
    "results.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f403f-b246-4706-a4c6-5f17be224048",
   "metadata": {},
   "source": [
    "¿Qué diferencias puedes observar entre los *p-values* de una regresión múltiple y los encontrados en las regresiones simples? ¿Por qué crees que existen estas diferencias?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6918265e",
   "metadata": {},
   "source": [
    "Los p-values cambian porque la regresión múltiple evalúa el efecto de cada variable controlando las demás, mientras que la regresión simple solo analiza relaciones individuales, lo que puede quitar  la importancia de algunas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898858d-5dda-42ae-b458-b5e7fcd2df76",
   "metadata": {},
   "source": [
    "## Referencia\n",
    "\n",
    "James, G., Witten, D., Hastie, T., Tibshirani, R.,, Taylor, J. (2023). An Introduction to Statistical Learning with Applications in Python. Cham: Springer. ISBN: 978-3-031-38746-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72b870-2174-4ea9-adac-260d6aa97067",
   "metadata": {},
   "source": [
    "## Addendum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dacc515-40ee-4ac8-a6f6-9e1a22b97313",
   "metadata": {},
   "source": [
    "Para calcular los *p-values* de los parámetros sin `statsmodels`:\n",
    "1. Calcular RSS\n",
    "2. Calcular RSE\n",
    "3. `var_beta = np.linalg.inv(X.T @ X) * rse**2` (X con columna de intercepto)\n",
    "4. `std_beta = np.sqrt(var_beta.diagonal())` El orden de los valores corresponde al orden de los factores en las columnas de la matriz $X$.\n",
    "5. Calcular *estadístico t*\n",
    "6. Calcular *p-value*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
