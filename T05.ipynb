{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33895ef-5285-4954-b60c-f2f2162c04aa",
   "metadata": {},
   "source": [
    "Regina Tamayo León\n",
    "\n",
    "Jueves 19 feb 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53174c5a-61df-4b6f-b4d8-9ab8d8d68501",
   "metadata": {},
   "source": [
    "*EDA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77a4063e-40c8-48e5-998c-65e94220058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "df=pd.read_excel(\"Motor Trend Car Road Tests.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1367a2-cc2f-4636-8324-a891feb6667c",
   "metadata": {},
   "source": [
    "**SECCIÓN 1: FACTORES COMO NUMÉRICOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d38f7d6b-0b69-4943-ad04-aad84fe303a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EJERCICIO 1.1: mpg (Numérico)\n",
      "R2 Modelo Completo: 0.8690\n",
      "Interpretación de Betas: [-0.11144048  0.01333524 -0.02148212  0.78711097 -3.71530393  0.82104075\n",
      "  0.31776281  2.52022689  0.65541302 -0.19941925]\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Regresión para 'mpg' \n",
    "print(\"EJERCICIO 1.1: mpg (Numérico)\")\n",
    "X1 = df.drop(columns=['mpg', 'model'])\n",
    "y1 = df['mpg']\n",
    "\n",
    "\n",
    "m1_full = LinearRegression().fit(X1, y1)\n",
    "print(f\"R2 Modelo Completo: {r2_score(y1, m1_full.predict(X1)):.4f}\")\n",
    "print(\"Interpretación de Betas:\", m1_full.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23377b1-6497-448b-b36b-7a5eed81ed59",
   "metadata": {},
   "source": [
    "La beta dice cuánto cambia la salida (mpg) por cada unidad que aumenta una variable, dejando las demás constantes.\n",
    "\n",
    "Signo Negativo (-): Existe una relación inversa. Por ejemplo, si la Beta del peso (wt) es -3.71, significa que por cada 1,000 libras adicionales de peso, el rendimiento baja 3.71 millas por galón.\n",
    "\n",
    "Signo Positivo (+): Existe una relación directa. Por ejemplo, si la Beta de transmisión manual (am) es 2.52, significa que un auto manual tiende a subir su rendimiento en 2.52 millas por galón frente a uno automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a977c902-cce8-468b-a012-ae81c4e91808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9982\n",
      "R2 Test (Sin regularización): -7.1071\n"
     ]
    }
   ],
   "source": [
    "# Split 40% entrenamiento \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, train_size=0.4, random_state=42)\n",
    "m1_split = LinearRegression().fit(X_train1, y_train1)\n",
    "print(f\"R2 Train: {r2_score(y_train1, m1_split.predict(X_train1)):.4f}\")\n",
    "print(f\"R2 Test (Sin regularización): {r2_score(y_test1, m1_split.predict(X_test1)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "885ff4ba-2b85-4556-b3a3-d9c53d32db26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparativa Ridge (Lambda):\n",
      "Lambda 0.1 -> R2 Test: 0.2607\n",
      "Lambda 1.0 -> R2 Test: 0.6311\n",
      "Lambda 10.0 -> R2 Test: 0.6567\n",
      "Lambda 100.0 -> R2 Test: 0.5990\n"
     ]
    }
   ],
   "source": [
    "# Regularización L2 (Ridge) \n",
    "print(\"Comparativa Ridge (Lambda):\")\n",
    "for L in [0.1, 1.0, 10.0, 100.0]:\n",
    "    ridge = Ridge(alpha=L).fit(X_train1, y_train1)\n",
    "    print(f\"Lambda {L} -> R2 Test: {r2_score(y_test1, ridge.predict(X_test1)):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703bec8c-c27f-4b5b-8548-4817051ad6e4",
   "metadata": {},
   "source": [
    "Con la regresión lineal simple y su  $R^2$ (-7.10), al usar Lambda 10.0 o 100.0, el $R^2$ de prueba se vuelve positivo (0.65).Porque al restringir los coeficientes, el modelo deja de memorizar los 12 autos de entrenamiento y su capacidad para generalizar con los datos de prueba mejora drásticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59a65a4e-730a-40ce-baa8-3175a494c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EJERCICIO 1.2: qsec (Numérico)\n",
      "R2 Modelo Completo: 0.8747\n",
      "R2 Test (Sin regularización): -1.0013\n",
      "Comparativa Ridge (Lambda):\n",
      "Lambda 0.1 -> R2 Test: 0.6878\n",
      "Lambda 1.0 -> R2 Test: 0.7141\n",
      "Lambda 10.0 -> R2 Test: 0.5044\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Regresión para 'qsec' \n",
    "print(\"EJERCICIO 1.2: qsec (Numérico)\")\n",
    "X2 = df.drop(columns=['qsec', 'model'])\n",
    "y2 = df['qsec']\n",
    "\n",
    "m2_full = LinearRegression().fit(X2, y2)\n",
    "print(f\"R2 Modelo Completo: {r2_score(y2, m2_full.predict(X2)):.4f}\")\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, train_size=0.4, random_state=42)\n",
    "m2_split = LinearRegression().fit(X_train2, y_train2)\n",
    "print(f\"R2 Test (Sin regularización): {r2_score(y_test2, m2_split.predict(X_test2)):.4f}\")\n",
    "\n",
    "\n",
    "print(\"Comparativa Ridge (Lambda):\")\n",
    "for L in [0.1, 1.0, 10.0]:\n",
    "    ridge = Ridge(alpha=L).fit(X_train2, y_train2)\n",
    "    print(f\"Lambda {L} -> R2 Test: {r2_score(y_test2, ridge.predict(X_test2)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad7293-2a67-4da3-9ff0-5c5604d76e0e",
   "metadata": {},
   "source": [
    "El resultado negativo (-1) me indica que el modelo está sobreajustado y no sirve para predecir autos que no conoce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cc60c-1bb5-4900-9ea0-f0a9664a5ead",
   "metadata": {},
   "source": [
    "Para qsec, el punto ideal podría ser cerca de Lambda 1.0.Si el Lambda es muy bajo, el modelo es inestable.Si el Lambda es muy alto (ej. 10.0), el $R^2$ de prueba puede empezar a bajar (0.50), porque la aceleración es un fenómeno físico muy sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2568a37-3f4f-488f-9ade-1d3eb188264d",
   "metadata": {},
   "source": [
    "**SECCIÓN 2: FACTORES COMO DUMMIES (cyl, gear, carb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c68d4b11-ced7-4f8d-9c30-878f1c70f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EJERCICIO 2.1: mpg (Dummies)\n",
      "R2 Modelo Completo con Dummies: 0.8931\n",
      "R2 Test (Dummies): -1.3253\n"
     ]
    }
   ],
   "source": [
    "df_dummies = pd.get_dummies(df, columns=['cyl', 'gear', 'carb'], drop_first=True)\n",
    "\n",
    "# 2.1 Regresión para 'mpg' con Dummies\n",
    "print(\"EJERCICIO 2.1: mpg (Dummies)\")\n",
    "X3 = df_dummies.drop(columns=['mpg', 'model'])\n",
    "y3 = df_dummies['mpg']\n",
    "\n",
    "m3_full = LinearRegression().fit(X3, y3)\n",
    "r2_21_full = r2_score(y3, m3_full.predict(X3))\n",
    "print(f\"R2 Modelo Completo con Dummies: {r2_21_full:.4f}\")\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, train_size=0.4, random_state=42)\n",
    "m3_split = LinearRegression().fit(X_train3, y_train3)\n",
    "print(f\"R2 Test (Dummies): {r2_score(y_test3, m3_split.predict(X_test3)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbfac85-c7ed-49cc-a88f-c2696ad572ac",
   "metadata": {},
   "source": [
    "Este número es muy bueno: al convertir los cilindros, las marchas y los carburadores en Dummies (categorías independientes), el modelo ahora entiende el 89.31% de la realidad de los autos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362948e-e4e8-46b4-8112-b5b67e5e8f7a",
   "metadata": {},
   "source": [
    "Un $R^2$ negativo significa que mi modelo es malo prediciendo datos nuevos, que sería más exacto simplemente adivinar el promedio que usarlo. Pero al crear las Dummies, le di muchísimas variables (columnas).El modelo tiene demasiadas herramientas para tan pocos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc1305ee-31f7-4ab4-b09f-a683191b3030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EJERCICIO 2.2: qsec (Dummies)\n",
      "R2 Modelo Completo con Dummies: 0.9083\n",
      "R2 Test (Dummies): -0.0600\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Regresión para 'qsec' con Dummies\n",
    "print(\"EJERCICIO 2.2: qsec (Dummies)\")\n",
    "X4 = df_dummies.drop(columns=['qsec', 'model'])\n",
    "y4 = df_dummies['qsec']\n",
    "\n",
    "m4_full = LinearRegression().fit(X4, y4)\n",
    "r2_22_full = r2_score(y4, m4_full.predict(X4))\n",
    "print(f\"R2 Modelo Completo con Dummies: {r2_22_full:.4f}\")\n",
    "\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4, train_size=0.4, random_state=42)\n",
    "m4_split = LinearRegression().fit(X_train4, y_train4)\n",
    "print(f\"R2 Test (Dummies): {r2_score(y_test4, m4_split.predict(X_test4)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51549db9-b342-4ab6-a80c-4fdaf4ef74a0",
   "metadata": {},
   "source": [
    "qsec depende totalmente de la configuración específica del motor (cilindros y carburadores). Tratar estos factores como categorías independientes es mucho más exacto que tratarlos como números."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d477eeab-1aca-4db5-8571-d9e45d54b436",
   "metadata": {},
   "source": [
    "**SECCIÓN 3: COMPARACIONES FINALES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b616d6-96c4-48d2-a370-ca39c418934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESUMEN DE COMPARACIONES\n",
      "3.1 MPG: Simple R2 (0.8690) vs Dummies R2 (0.8931)\n",
      "3.2 QSEC: Simple R2 (0.8747) vs Dummies R2 (0.9083)\n"
     ]
    }
   ],
   "source": [
    "print(\"RESUMEN DE COMPARACIONES\")\n",
    "print(f\"3.1 MPG: Simple R2 ({r2_score(y1, m1_full.predict(X1)):.4f}) vs Dummies R2 ({r2_21_full:.4f})\")\n",
    "print(f\"3.2 QSEC: Simple R2 ({r2_score(y2, m2_full.predict(X2)):.4f}) vs Dummies R2 ({r2_22_full:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a17f5-3986-4d17-9b37-0f06262d84bf",
   "metadata": {},
   "source": [
    "En ambas variables de salida (mpg y qsec), el uso de variables Dummy demostró ser la mejor estrategia para modelar el comportamiento de los automóviles, obteniendo los coeficientes de determinación ($R^2$) más altos. \n",
    "Este aumento en la precisión requiere un manejo cuidadoso de la complejidad (mediante Ridge) para evitar que el modelo se vuelva inestable al predecir datos fuera de la muestra de entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
